---
title: "Digital Soil Mapping Report"
author: "Amanda Cole"
date: "2023-12-19"
output:
  html_document:
    code_folding: hide
  pdf_document: default
---
---
# 5.1 Simple Model
```{r message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2)
library(recipes)
library(tidyverse)
library(dplyr)
library(knitr)
library(caret)
```
```{r include=FALSE, warning=FALSE, message=FALSE}
### Load Data
df_full <- readRDS(here::here("data/df_full.rds"))

head(df_full) |>
  knitr::kable()

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

I prepared the data following the exercise as detailed in the Data_Preparation file in the analysis folder. I then load the prepared data and set the target to waterlog.100, a binary categorical variable which contains values of 0 and 1 indicating whether the soil is waterlogged at 100cm depth. I set the predictors to include all predictors in the covariates dataset. I then split the dataset into training and test sets. 
```{r, class.source= 'fold-show'}
## Specify target: Waterlog.100
target <- "waterlog.100"

## Specify predictors_all
predictors_all <- names(df_full)[14:ncol(df_full)]
```

```{r echo=FALSE}
cat("The target is:", target,
    "\nThe predictors_all are:", paste0(predictors_all[1:8], sep = ", "), "...")
```

```{r echo=TRUE, class.source= 'fold-show'}
# Splitting dataset into training and testing sets
df_train <- df_full |> dplyr::filter(dataset == "calibration")
df_test  <- df_full |> dplyr::filter(dataset == "validation")

# Filtering out any NAs
df_train <- df_train |> tidyr::drop_na()
df_test <- df_test   |> tidyr::drop_na()
```

```{r echo=FALSE}
n_tot <- nrow(df_train) + nrow(df_test)

perc_cal <- (nrow(df_train) / n_tot) |> round(2) * 100
perc_val <- (nrow(df_test)  / n_tot) |> round(2) * 100

cat("For model training, we have a calibration / validation split of: ",
    perc_cal, "/", perc_val, "%")
```

After splitting the data into training and test sets, I then trained a Random Forest model using the {ranger} package. Because we are predicting for a categorical variable, this will be a classification model so I set "classification" = TRUE.
```{r echo=TRUE, class.source= 'fold-show'}
rf_basic <- ranger::ranger(
  probability = FALSE,
  classification = TRUE,
  y = df_train[, target],     # Target variable
  x = df_train[, predictors_all], # Predictor variables
  seed = 42,                    # Specifying seed for randomization
  num.threads = parallel::detectCores() - 1) 
```
```{r echo=FALSE}
# Print a summary of fitted model
print(rf_basic)
```

I then evaluated the RF classification model on the testing set and saved the predictions to the test data. 
```{r echo=TRUE}
# Load area to be predicted
raster_mask <- terra::rast(here::here("data-raw/geodata/study_area/area_to_be_mapped.tif"))
# Turn target raster into a dataframe, 1 px = 1 cell
df_mask <- as.data.frame(raster_mask, xy = TRUE)

# Filter only for area of interest
df_mask <- df_mask |>
  dplyr::filter(area_to_be_mapped == 1)

# Display df
head(df_mask) |>
  knitr::kable()

files_covariates <- list.files(
  path = here::here("data-raw/geodata/covariates/"),
  pattern = ".tif$",
  recursive = TRUE,
  full.names = TRUE
)

# Filter for variables used in RF
preds_all <- names((df_train[, predictors_all]))
files_selected <- files_covariates[apply(sapply(X = preds_all,
                                                FUN = grepl,
                                                files_covariates),
                                         MARGIN =  1,
                                         FUN = any)]

# Load all rasters as a stack
raster_covariates <- terra::rast(files_selected)

# Get coordinates
df_locations <- df_mask |>
  dplyr::select(x, y)

# Extract data from covariate raster stack for all gridcells in the raster
df_predict <- terra::extract(
  raster_covariates,  
  df_locations,       
  ID = FALSE           
)

df_predict <- cbind(df_locations, df_predict) |>
  tidyr::drop_na() 
```
```{r echo=TRUE, class.source= 'fold-show'}
# Make predictions for validation sites
prediction <- predict(
  rf_basic,           # RF model
  data = df_test,   # Predictor data
  num.threads = parallel::detectCores() - 1
)
```
```{r echo=TRUE}
# Save predictions to validation df
df_test$pred <- prediction$predictions
```
The model is fairly well balanced in terms of TRUE and FALSE values, with 73 "TRUE" values (36.5%) and 127 "FALSE" values (63.5%). This means that Accuracy, a measure of the proportion of outputs that were correctly classified^1^, is an appropriate metric to use to measure the quality of our model. If the model was imbalanced, Accuracy would not be an appropriate metric to use. 

Other useful metrics for classification include Precision, a measure of the proportion of predictions that were correct out of the total number of predictions^2^; Sensitivity,  a measure of the proportion of real positives that the model correctly predicted^2^, or the True Positive Rate (True Positives/True Positives + False Negatives); False Positive Rate, a measure of the proportion of real negatives that the model classified as positive (False Positives/False Positives + True Negatives)^1^; Specificity, which is a measure of the proportion of true negatives that the model was able to capture^2^; and and the F1 score which is defined as the harmonic mean of precision and sensitivity^1^. The Receiver Operating Characteristic (ROC) curve is also commonly used to evaluate classification models and is composed by plotting the True Positive Rate against the False Positive Rate. This allows you to determine trade-offs between sensitivity and specificity across various classification thresholds^2^. The Area Under the Curve (AUC), defined as the area between the ROC curve and the x-axis, can be used to assess the model performance across the thresholds with a range of 0 to 1, with 1 representing perfect classification and AUC values of closer to 0.5 representing essentially a random classifier^1,2^.

I used the {caret} package to create a Confusion Matrix which includes the necessary metrics.
```{r echo=FALSE}
# Classification Metrics
Y <- df_test$waterlog.100
Y <- as.factor(Y)
X <- df_test$pred
X <- as.factor(X)

#Confusion Matrix
conf_matrix_waterlog_rfbasic <- caret::confusionMatrix(data=X, reference=Y, positive="1")
conf_matrix_waterlog_rfbasic
mosaicplot(conf_matrix_waterlog_rfbasic$table,
           main = "Confusion Matrix for Simple Random Forest Model")
```

As reported by the confusion matrix above, our simple model using all predictors and pre-defined hyperparameters produced an Accuracy of 0.75. The Sensitivity was 0.6714, meaning that our model correctly predicted ~67.14% of true positive and the Specificity was 0.7923, meaning that our model correctly predicted ~97.23 of true negatives. 

Finally, I used the model to create predictions for the entire study area and mapped these. As you can see from the below map, the soil was predicted to be waterlogged in the south west and there are more areas predicted to be not waterlogged in the north east.
```{r echo=FALSE}
df_predict$vszone <- trimws(df_predict$vszone) #vszone tif was reading in with missing values, this fixed the issue.
```
```{r echo=TRUE, class.source= 'fold-show'}
prediction <- predict(
  rf_basic,              # RF model
  data = df_predict,
  num.threads = parallel::detectCores() - 1)
```

```{r echo=FALSE}
# Attach predictions to dataframe and round them
df_predict$prediction <- prediction$predictions

# Extract dataframe with coordinates and predictions
df_map <- df_predict |>
  dplyr::select(x, y, prediction)

# Turn dataframe into a raster
raster_pred <- terra::rast(
  df_map,                  
  crs = "+init=epsg:2056", 
  extent = terra::ext(raster_covariates)
)

#Plot
ggplot2::ggplot() +
  tidyterra::geom_spatraster(data = raster_pred) +
  ggplot2::scale_fill_viridis_c(
    breaks = seq(0,1, by=1),
    labels = c("0", "1"),
    na.value = NA,
    option = "viridis",
    name = "Waterlog.100",
  ) +
  ggplot2::theme_classic() +
  ggplot2::scale_x_continuous(expand = c(0, 0)) +
  ggplot2::scale_y_continuous(expand = c(0, 0)) +
  ggplot2::labs(title = "Predicted Waterlog Map for Simple Random Forest Model")
```


# 5.2 Variable Selection

Using all available predictors to train a model increases the risk of overfitting, i.e. the model reflects not just the true underlying pattern or relationship in the data but also observation errors or random fluctuations in the data^1^. By identifying and selecting on the models that are most important, variance can be reduced and model generalisability (the model's ability to make predictions on unseen data) improves.

I first used the {ranger} package, setting "importance" = permutation to calculate variable importance. This will permute or randomly shuffle a predictors values and measure the impact on model performance to determine the impact on model performance.
```{r echo=TRUE, class.source= 'fold-show'}
### Variable Importance
rf_varimport <- ranger::ranger(
  probability = FALSE,
  y = df_train[, target],     # target variable
  x = df_train[, predictors_all],   # Predictor variables
  importance   = "permutation",
  classification = TRUE,
  seed = 42,                    # Specify seed for randomization 
  num.threads = parallel::detectCores() - 1) 
```

```{r echo=FALSE}
# Extract the variable importance and create a long tibble
vi_rf_varimport <- rf_varimport$variable.importance |>
  dplyr::bind_rows() |>
  tidyr::pivot_longer(cols = dplyr::everything(), names_to = "Variable")
```

The below bar graph shows the order of importance of the variables. Higher values reflect a stronger the effect of permutation and higher importance of the variables.

```{r echo=FALSE}
# Plot variable importance, ordered by decreasing value
gg <- vi_rf_varimport |>
  ggplot2::ggplot(ggplot2::aes(x = reorder(Variable, value), y = value)) +
  ggplot2::geom_bar(stat = "identity", fill = "grey50", width = 0.75) +
  ggplot2::labs(
    y = "Change in OOB accuracy after permutation",
    x = "",
    title = "Variable importance based on OOB") +
  ggplot2::theme(text=element_text(size=7))+
  ggplot2::coord_flip()

# Display plot
gg
```

The five most important variables were as follows: 
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Extract the variable importance and create a long tibble
vi_rf_varimport <- rf_varimport$variable.importance |>
  dplyr::bind_rows() |>
  tidyr::pivot_longer(cols = dplyr::everything(), names_to = "Variable")

vi_rf_varimport_top5 <- vi_rf_varimport |> 
  top_n(5, value)

vi_rf_varimport_top5 <- vi_rf_varimport_top5 |>
  arrange(desc(value))

vi_rf_varimport_top5 <- vi_rf_varimport_top5 |>
  mutate(Importance = row_number())

vi_rf_varimport_top5 <- vi_rf_varimport_top5 |>
  rename(Value = value)

vi_rf_varimport_top5 <- vi_rf_varimport_top5 |>
  select(Importance, Variable, Value)

library(knitr)
kable(vi_rf_varimport_top5)
```

I then used the {Boruta} package to perform a permutation of the values to determine their importance. 
```{r echo=FALSE}
### Variable Selection
set.seed(42)
```
```{r echo=TRUE, class.source= 'fold-show'}
# run the algorithm
bor <- Boruta::Boruta(
  y = df_train[, target],
  x = df_train[, predictors_all],
  maxRuns = 50, 
  num.threads = parallel::detectCores()-1)
```
```{r echo=FALSE}
# obtain results: a data frame with all variables, ordered by their importance
df_bor <- Boruta::attStats(bor) |>
  tibble::rownames_to_column() |>
  dplyr::arrange(dplyr::desc(meanImp))
```

The variables deemed important "Confirmed" are shown in orange below.
```{r echo=FALSE}
ggplot2::ggplot(ggplot2::aes(x = reorder(rowname, meanImp),
                             y = meanImp,
                             fill = decision),
                data = df_bor) +
  ggplot2::geom_bar(stat = "identity", width = 0.75) +
  ggplot2::scale_fill_manual(values = c("grey30", "tomato", "grey70")) +
  ggplot2::labs(
    y = "Variable importance",
    x = "",
    title = "Variable importance based on Boruta") +
  ggplot2::theme(text=element_text(size=7)) +
  ggplot2::coord_flip()
```

The Boruta algorithm categorized 37 variables as "Confirmed". The variables deemed important by the Boruta algorithm were largely the same as those identified by the {ranger} package. I then retrained the Random Forest model using the 39 variables deemed important by the Boruta algorithm.
```{r echo=TRUE}
# get retained important variables
predictors_selected <- df_bor |>
  dplyr::filter(decision == "Confirmed") |>
  dplyr::pull(rowname)
length(predictors_selected)
```
```{r echo=TRUE, class.source= 'fold-show'}
# re-train Random Forest model
rf_bor <- ranger::ranger(
  probability = FALSE,
  y = df_train[, target],              # target variable
  x = df_train[, predictors_selected], # Predictor variables
  classification = TRUE,
  seed = 42,                           # Specify the seed for randomization
  num.threads = parallel::detectCores() - 1) 
```
```{r echo=FALSE}
rf_bor
```

I then evaluated the model on the testing subset of the data and created a confusion matrix with the relevant metrics.
```{r include=FALSE}
# Load area to be predicted
raster_mask <- terra::rast(here::here("data-raw/geodata/study_area/area_to_be_mapped.tif"))
# Turn target raster into a dataframe, 1 px = 1 cell
df_mask <- as.data.frame(raster_mask, xy = TRUE)

# Filter only for area of interest
df_mask <- df_mask |>
  dplyr::filter(area_to_be_mapped == 1)

files_covariates <- list.files(
  path = here::here("data-raw/geodata/covariates/"),
  pattern = ".tif$",
  recursive = TRUE,
  full.names = TRUE
)

# Filter that list only for the variables used in the RF
preds_selected <- names(df_train[, predictors_selected])
files_selected <- files_covariates[apply(sapply(X = preds_selected,
                                                FUN = grepl,
                                                files_covariates),
                                         MARGIN =  1,
                                         FUN = any)]

# Load all rasters as a stack
raster_covariates <- terra::rast(files_selected)

# Get coordinates for which we want data
df_locations <- df_mask |>
  dplyr::select(x, y)

# Extract data from covariate raster stack for all gridcells in the raster
df_predict <- terra::extract(
  raster_covariates,  
  df_locations,        
  ID = FALSE           
)

df_predict <- cbind(df_locations, df_predict) |>
  tidyr::drop_na()  
```

```{r echo=TRUE, class.source= 'fold-show'}
# Make predictions for validation sites
prediction <- predict(
  rf_bor,           # RF model
  data = df_test,   # Predictor data
  num.threads = parallel::detectCores() - 1
)
```

```{r echo=FALSE}
# Save predictions to validation df
df_test$pred <- prediction$predictions
```

```{r echo=FALSE}
# Classification Metrics
Y <- df_test$waterlog.100
Y <- as.factor(Y)
X <- df_test$pred
X <- as.factor(X)

#Confusion Matrix
conf_matrix_waterlog_bor <- caret::confusionMatrix(data=X, reference=Y, positive="1")
conf_matrix_waterlog_bor
mosaicplot(conf_matrix_waterlog_rfbasic$table,
           main = "Confusion matrix")
```

As reported by the confusion matrix above, our model using predictors selected by the Boruta algorithm and pre-defined hyperparameters produced an Accuracy of 0.79. The Sensitivity was 0.7286, meaning that our model correctly predicted 72.86% of true positive and the Specificity was 0.8231, meaning that our model correctly predicted 82.31% of true negatives. 

The model trained using the predictors selected by the Boruta algorithm had a higher accuracy when evaluated on the testing subset than the simple model (0.79 vs 0.75 respectively. Therefore, the new model trained on the selected variables generalises better to unseen data than the simple model. 

However, when considering the OOB prediction error reported as part of the trained model object, the simple model actually has a better OOB prediction error than that of the model trained on the Boruta selected predictors (21.32% vs 20.99% respectively). 

The Predicted Waterlog map using the selected predictors is shown below.
```{r echo=FALSE}
### Create Prediction Maps
prediction <- predict(
  rf_bor,              # RF model
  data = df_predict,
  num.threads = parallel::detectCores() - 1)

# Attach predictions to dataframe
df_predict$prediction <- prediction$predictions

# Extract dataframe with coordinates and predictions
df_map <- df_predict |>
  dplyr::select(x, y, prediction)

# Turn dataframe into a raster
raster_pred <- terra::rast(
  df_map,                  
  crs = "+init=epsg:2056", 
  extent = terra::ext(raster_covariates) 
)

# Visualise predictions
ggplot2::ggplot() +
  tidyterra::geom_spatraster(data = raster_pred) +
  ggplot2::scale_fill_viridis_c(
    breaks = seq(0,1, by=1),
    labels = c("0", "1"),
    na.value = NA,
    option = "viridis",
    name = "Waterlog.100"
  ) +
  ggplot2::theme_classic() +
  ggplot2::scale_x_continuous(expand = c(0, 0)) +
  ggplot2::scale_y_continuous(expand = c(0, 0)) +
  ggplot2::labs(title = "Predicted Waterlog")
```

# 5.3 Model Optimization

For Random Forest algorithms, we can control the complexity and randomness of the RF through hyperparameters in the {ranger} package such as min.node.size, num.trees, and mtry. Hyperparameters have a large impact on model performance and sub-optimal hyperparameters can lead to over or under fitting or low generalisability^1^. While the Random Forest models above have fairly good accuracy with the pre-defined hyperparameters, I tuned the hyperparameters to try to improve model performance. I used the {caret} library to implement a 5-fold cross-validation to optimise hyperparameters m.try, min.node.size, and splitrule, using a greedy hyperparameter tuning approach and a grid hyperparameter approach.
```{r include=FALSE}
# Set recipe
set.seed(42)
df_train$waterlog.100 <- as.factor(df_train$waterlog.100)
pp <- recipes::recipe(waterlog.100 ~ NegO + mrvbf25 + mt_rr_y + Se_diss2m_50c + Se_TWI2m + Se_curv2m_s60 + be_gwn25_vdist + Se_MRVBF2m + lsf + Se_TWI2m_s15 + cindx10_25 + mt_td_y + Se_tpi_2m_50c + terrTextur + tsc25_40 + Se_NO2m_r500 + Se_curv2m_fmean_50c + Se_TWI2m_s60 + Se_slope50m + tsc25_18 + vdcn25 + Se_alti2m_std_50c + mt_tt_y + Se_curv50m + be_gwn25_hdist + Se_rough2m_10c + Se_curvplan2m_s60 + Se_diss2m_5c + Se_curvprof50m + Se_slope6m + Se_rough2m_5c + Se_curvplan50m + Se_slope2m_s7 + Se_slope2m_fmean_5c + Se_slope2m_fmean_50c, data = df_train)
```
After setting the possible mtry, min.node.size, and splitrule values, I optimized using a greedy hyperparameter approach first starting by optmizing min.node.size, keeping mtry constant at 6 (as the default value for mtry for a classification problem is the square root of the number of predictors) and splitrule constant to gini. 
```{r echo=TRUE, class.source= 'fold-show'}
### Greedy Hyperparameter Tuning
mtry_values <- c(2,3,4,5,6,7,8,9,10,12,14,16)
min.node.size_values <- c(2,5,10,20,25)
splitrule_values <- c("gini", "extratrees")

set.seed(42)
mod <- caret::train(
  pp,
  data = df_train %>%
    drop_na(),
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, savePredictions = "final"),
  tuneGrid = expand.grid( .mtry = 9,
                          .min.node.size = min.node.size_values,
                          .splitrule = "gini"),
  metric = "Accuracy",
  replace = FALSE,
  sample.fraction = 0.5,
  num.trees = 50,
  seed = 42                
)
```
```{r echo=FALSE}
print(mod)
```

Then I optimized mtry while keeping min.node.size and splitrule constant. 
```{r echo=TRUE, class.source= 'fold-show'}
set.seed(42)
mod <- caret::train(
  pp,
  data = df_train %>%
    drop_na(),
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, savePredictions = "final"),
  tuneGrid = expand.grid( .mtry = mtry_values,
                          .min.node.size = 5,
                          .splitrule = "gini"),
  metric = "Accuracy",
  replace = FALSE,
  sample.fraction = 0.5,
  num.trees = 50,
  seed = 42               
)
```
```{r echo=FALSE}
print(mod)
```
Then, used the best value for mtry and the best value for min.node.size obtained from the previous run and optimised splitrule.
```{r echo=TRUE, class.source= 'fold-show'}
set.seed(42)
mod <- caret::train(
  pp,
  data = df_train %>%
    drop_na(),
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, savePredictions = "final"),
  tuneGrid = expand.grid( .mtry = 12,
                          .min.node.size = 10,
                          .splitrule = splitrule_values),
  metric = "Accuracy",
  replace = FALSE,
  sample.fraction = 0.5,
  num.trees = 50,
  seed = 42                
)
```
```{r echo=FALSE}
print(mod)
```
I then retrained the model using the optimized hyperparameters.
```{r echo=TRUE, class.source= 'fold-show'}
mod_greedy <- caret::train(
  pp,
  data = df_train |>
    drop_na(),
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, savePredictions = "final"),
  tuneGrid = expand.grid( .mtry = 12,
                          .min.node.size = 10,
                          .splitrule = "gini"),
  metric = "Accuracy",
  replace = FALSE,
  sample.fraction = 0.5,
  num.trees = 100,
  seed = 42                
)
```
```{r echo=FALSE}
print(mod_greedy)
```
I then evaluated the model optimised using the greedy hyperparameter tuning approach on the testing subset of the data. 
```{r include=FALSE}
#### Model Analysis
mod_greedy   <- readRDS(here::here("data/rf_mod_greedy_for_waterlog.100.rds"))
df_train <- readRDS(here::here("data/cal_bor_for_waterlog.100.rds"))
df_test  <- readRDS(here::here("data/val_bor_for_waterlog.100.rds"))
```

```{r echo=TRUE, class.source= 'fold-show'}
# Make predictions for validation sites using model optimised through greedy approach
prediction <- predict(
  mod_greedy,           # RF model
  newdata = df_test,   # Predictor data
  num.threads = parallel::detectCores() - 1
)

# Save predictions to validation df
df_test$predcv <- prediction
```

```{r echo=FALSE}
# Classification Metrics
Y <- df_test$waterlog.100
Y <- as.factor(Y)
X <- df_test$predcv
X <- as.factor(X)

conf_matrix_waterlog_rfmodcv <- caret::confusionMatrix(data=X, reference=Y, positive="1")
conf_matrix_waterlog_rfmodcv
mosaicplot(conf_matrix_waterlog_rfbasic$table,
           main = "Confusion matrix")
```

The model accuracy obtained with the hyperparameters optimized using the greedy approach was 0.73. Therefore, this model does not generalise better to unseen data than the initial model which had an accuracy of 0.79.

I then used a grid hyperparameter tuning approach as below.
```{r include=FALSE}
## Grid Hyperparameter Tuning
set.seed(42)
df_train$waterlog.100 <- as.factor(df_train$waterlog.100)
pp <- recipes::recipe(waterlog.100 ~ NegO + mrvbf25 + mt_rr_y + Se_diss2m_50c + Se_TWI2m + Se_curv2m_s60 + be_gwn25_vdist + Se_MRVBF2m + lsf + Se_TWI2m_s15 + cindx10_25 + mt_td_y + Se_tpi_2m_50c + terrTextur + tsc25_40 + Se_NO2m_r500 + Se_curv2m_fmean_50c + Se_TWI2m_s60 + Se_slope50m + tsc25_18 + vdcn25 + Se_alti2m_std_50c + mt_tt_y + Se_curv50m + be_gwn25_hdist + Se_rough2m_10c + Se_curvplan2m_s60 + Se_diss2m_5c + Se_curvprof50m + Se_slope6m + Se_rough2m_5c + Se_curvplan50m + Se_slope2m_s7 + Se_slope2m_fmean_5c + Se_slope2m_fmean_50c, data = df_train)
```
```{r echo=TRUE, class.source= 'fold-show'}
## Grid Hyperparameter Tuning
mod_grid <- caret::train(
  pp,
  data = df_train|>
    drop_na(),
  method = "ranger",
  trControl = trainControl(method = "cv", number = 5, savePredictions = "final"),
  tuneGrid = expand.grid( .mtry = mtry_values,
                          .min.node.size = min.node.size_values,
                          .splitrule = splitrule_values),
  metric = "Accuracy",
  replace = FALSE,
  sample.fraction = 0.5,
  num.trees = 100,
  seed = 42               
)
print(mod_grid)
```

The final values obtained using a grid hyperparameter tuning approach are reported above. I evaluated the model optimised using the grid hyperparameter tuning approach on the testing subset of the data. 
```{r include=FALSE, class.source= 'fold-show'}
#### Model Analysis
mod_grid   <- readRDS(here::here("data/rf_mod_grid_for_waterlog.100.rds"))
df_train <- readRDS(here::here("data/cal_bor_for_waterlog.100.rds"))
df_test  <- readRDS(here::here("data/val_bor_for_waterlog.100.rds"))

```{r echo=TRUE}
### Evaluation
# Make predictions for validation sites using greedy model
set.seed(42)
prediction <- predict(
  mod_grid,
  newdata = df_test,
  seed = 42,
  num.threads = parallel::detectCores() - 1
)

# Save predictions to validation df
df_test$predcv <- prediction
```
```{r echo=FALSE}
# Classification Metrics
Y <- df_test$waterlog.100
Y <- as.factor(Y)
X <- df_test$predcv
X <- as.factor(X)

conf_matrix_waterlog_rfmodcv <- caret::confusionMatrix(data=X, reference=Y, positive="1")
conf_matrix_waterlog_rfmodcv
mosaicplot(conf_matrix_waterlog_rfmodcv$table, main = "Confusion matrix")
```

Neither the grid nor the greedy hyperparameter tuning approaches resulted in a model that had a higher accuracy than the boruta algorithm trained with the default hyperparameters of mtry=6, min.node.size=1, and splitrule=gini. The optimal min.node.size found by both the greedy and grid hyperparameter tuning approaches were higher than the default min.node.size of 1 and as higher min.node.sizes should increase model generalisability resulting in a model that performs better on the new testing data^1^, we would expect a higher accuracy when evaluating the model on the testing subset of the data, however this was not the case.

# 5.4 Probabalistic Predictions
To predict the probability of the soil to be waterlogged, I trained a probabalistic random forest model by setting probabilty=TRUE as below and made predictions for the validation sites.
```{r echo=FALSE}
predictors_selected <- c("NegO", "mrvbf25", "mt_rr_y", "Se_diss2m_50c", "Se_TWI2m", "Se_curv2m_s60", "be_gwn25_vdist", "Se_MRVBF2m", "lsf",
  "Se_TWI2m_s15", "cindx10_25", "mt_td_y", "Se_tpi_2m_50c", "terrTextur", "tsc25_40", "Se_NO2m_r500", "Se_curv2m_fmean_50c", "Se_TWI2m_s60",
  "Se_slope50m", "tsc25_18", "vdcn25", "Se_alti2m_std_50c", "mt_tt_y", "Se_curv50m", "be_gwn25_hdist", "Se_rough2m_10c", "Se_curvplan2m_s60",
  "Se_diss2m_5c", "Se_curvprof50m", "Se_slope6m", "Se_rough2m_5c", "Se_curvplan50m", "Se_slope2m_s7", "Se_slope2m_fmean_5c",
  "Se_slope2m_fmean_50c")
```
```{r echo=TRUE, class.source= 'fold-show'}
rf_prob <- ranger::ranger(
probability = TRUE,
classification = TRUE,
y = df_train[, "waterlog.100"],     # target variable
x = df_train[, predictors_selected], # Predictor variables
seed = 42,                    # Specify seed
num.threads = parallel::detectCores() - 1) 
```
```{r echo=FALSE}
# Print a summary of fitted model
print(rf_prob)
```

```{r include=FALSE}
# Load area to be predicted
raster_mask <- terra::rast(here::here("data-raw/geodata/study_area/area_to_be_mapped.tif"))
# Turn target raster into a dataframe, 1 px = 1 cell
df_mask <- as.data.frame(raster_mask, xy = TRUE)

# Filter only for area of interest
df_mask <- df_mask |>
  dplyr::filter(area_to_be_mapped == 1)

# Display df
head(df_mask) |>
  knitr::kable()

files_covariates <- list.files(
  path = here::here("data-raw/geodata/covariates/"),
  pattern = ".tif$",
  recursive = TRUE,
  full.names = TRUE
)

random_files <- sample(files_covariates, 2)
terra::rast(random_files[1])
terra::rast(random_files[2])

# Load all rasters as a stack
raster_covariates <- terra::rast(random_files)

# Get coordinates for which we want data
df_locations <- df_mask |>
  dplyr::select(x, y)

# Extract data from covariate raster stack for all gridcells in the raster
df_predict <- terra::extract(
  raster_covariates,   
  df_locations,       
  ID = FALSE           
)

df_predict <- cbind(df_locations, df_predict) |>
  tidyr::drop_na() 
```

```{r echo=TRUE, class.source= 'fold-show'}
# Make predictions for validation sites
prediction <- predict(
  rf_prob,           # RF model
  data = df_test,   # Predictor data
  type="response",
  num.threads = parallel::detectCores() - 1
)
```
```{r echo=FALSE}
# Save predictions to validation df
df_test$pred <- prediction$predictions
predictions <- prediction$predictions
```
To assess the performance of the model across various thresholds, I created the below Reciever Operating Curve with the True Positive Rate plotted against the False Positive Rate. Lower thresholds have higher TPR and FPRs.
```{r echo=FALSE}
library(plotROC)
```
```{r echo=FALSE}
#ROC Curve
basicplot <- ggplot(df_test, aes(d=waterlog.100, m=pred[,1])) + geom_roc()
basicplot
```

In cases where waterlogged soils severely jeopardize the stability of the building I would set a high threshold because we want to ensure that soils that have a possibility of being waterlogged as classified as waterlogged and that the highest number of true positives are captured even at the expense of a high number of false positives. In cases where waterlogged soils are unwanted but not critical, we can set a lower threshold to avoid unnecessary delays that could result from false positives. A similar analogy to another field is that of medical testing. In medical testing if a disease is life-threatening, you would want to set a high threshold to ensure as many true positives are captured to be able to act early and this is worth it even if the patient recieves a false alarm. If the disease is less critical, the threshold can be lower as the consequences of not capturing as many true positives are less severe. 

References

^1^ Benjamin Stocker, Koen Hufkens, Pepa Arán, & Pascal Schneider. Applied Geodata Science (v1.0), Zenodo, 2019. https://geco-bern.github.io/agds/.

^2^ Kuhn, Max and Johnson, Kjell. Feature Engineering and Selection: A Practical Approach for Predictive Models, Taylor & Francis, 2019. https://bookdown.org/max/FES/.
